{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
    "            img = cv2.imread(os.path.join(directory, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "def load_queries(directory):\n",
    "    queries = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                # Read all lines and strip newline characters\n",
    "                query = [int(line.strip()) for line in file]\n",
    "            queries.append((query[0],query[1:]))\n",
    "    return queries\n",
    "\n",
    "def load_results(directory):\n",
    "    queries = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\"t.txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                # Read all lines and strip newline characters\n",
    "                query = [line.strip() for line in file]\n",
    "            queries.append(\" | \".join(query[1:]))\n",
    "    return queries\n",
    "\n",
    "def load_lane_pins(directory):\n",
    "    pins_list = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                pins = [line.strip().split(',') for line in file]\n",
    "                pins = [tuple([int(num) for num in sublist]) for sublist in pins]\n",
    "            pins_list.append(pins)\n",
    "    return pins_list\n",
    "\n",
    "def display_image(image):\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(chosen_model, img, classes=[], conf=0.5):\n",
    "    if classes:\n",
    "        results = chosen_model.predict(img, classes=classes, conf=conf)\n",
    "    else:\n",
    "        results = chosen_model.predict(img, conf=conf)\n",
    "\n",
    "    return results\n",
    "\n",
    "def predict_and_detect(chosen_model, img, classes=[], conf=0.5):\n",
    "    results = predict(chosen_model, img, classes, conf=conf)\n",
    "\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cv2.rectangle(img, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 0), 2)\n",
    "            cv2.putText(img, f\"{result.names[int(box.cls[0])]}\",\n",
    "                        (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 1)\n",
    "    return img, results\n",
    "\n",
    "def get_sorted_pins_position(model, image, classes=[], conf=0.5, verbose=0):\n",
    "    pin_pos = []\n",
    "    if verbose == 1:\n",
    "        img,results = predict_and_detect(model, image, classes, conf)\n",
    "        display_image(img)\n",
    "    else:\n",
    "        results = predict(model, image, classes, conf)\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            left, top, right, buttom = box.xyxy[0]\n",
    "            pin_pos.append((int(left), int(top), int(right), int(buttom)))\n",
    "    return sorted(pin_pos, key=lambda x: (x[3], x[0]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template_matching(image, template):\n",
    "    # Apply template matching\n",
    "    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "    # Get the best match position\n",
    "    _, max_val, _, max_loc = cv2.minMaxLoc(result)\n",
    "    return max_val, max_loc\n",
    "\n",
    "def classify_lane(image, lane1_template, lane2_template, lane3_template, lane4_template):\n",
    "    max_val1, max_loc1 = template_matching(image, lane1_template)\n",
    "    max_val2, max_loc2 = template_matching(image, lane2_template)\n",
    "    max_val3, max_loc3 = template_matching(image, lane3_template)\n",
    "    max_val4, max_loc4 = template_matching(image, lane4_template)\n",
    "\n",
    "    print(f\"Matching score for lane 1: {max_val1}\")\n",
    "    print(f\"Matching score for lane 2: {max_val2}\")\n",
    "    print(f\"Matching score for lane 3: {max_val3}\")\n",
    "    print(f\"Matching score for lane 4: {max_val4}\")\n",
    "\n",
    "    max_val = max(max_val1, max_val2, max_val3, max_val4)\n",
    "\n",
    "    # Determine which lane the photo belongs to\n",
    "    if max_val1 == max_val:\n",
    "        return 1, max_val1, max_loc1\n",
    "    elif max_val2 == max_val:\n",
    "        return 2, max_val2, max_loc2\n",
    "    elif max_val3 == max_val:\n",
    "        return 3, max_val3, max_loc3\n",
    "    elif max_val4 == max_val:\n",
    "        return 4, max_val4, max_loc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectangle_area(rect):\n",
    "    \"\"\"\n",
    "    Calculate the area of a rectangle.\n",
    "    \n",
    "    rect should be a tuple or list in the format (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = rect\n",
    "    return max(0, xmax - xmin) * max(0, ymax - ymin)\n",
    "\n",
    "def intersection_area(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Calculate the area of intersection between two rectangles.\n",
    "    \n",
    "    rect1 and rect2 should be tuples or lists in the format (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    xmin1, ymin1, xmax1, ymax1 = rect1\n",
    "    xmin2, ymin2, xmax2, ymax2 = rect2\n",
    "\n",
    "    # Calculate the coordinates of the intersection rectangle\n",
    "    ixmin = max(xmin1, xmin2)\n",
    "    iymin = max(ymin1, ymin2)\n",
    "    ixmax = min(xmax1, xmax2)\n",
    "    iymax = min(ymax1, ymax2)\n",
    "\n",
    "    # Compute the width and height of the intersection rectangle\n",
    "    iw = max(0, ixmax - ixmin)\n",
    "    ih = max(0, iymax - iymin)\n",
    "\n",
    "    # Return the area of the intersection rectangle\n",
    "    return iw * ih\n",
    "\n",
    "def find_best_matching_rectangle(target_rect, rectangles):\n",
    "    \"\"\"\n",
    "    Find the rectangle from the list that shares the most area with the target rectangle.\n",
    "    \n",
    "    target_rect should be a tuple or list in the format (xmin, ymin, xmax, ymax).\n",
    "    rectangles should be a list of tuples/lists in the same format.\n",
    "    \"\"\"\n",
    "    max_intersection_area = 0\n",
    "    best_match = (0,0,0,0)\n",
    "\n",
    "    for rect in rectangles:\n",
    "        area = intersection_area(target_rect, rect)\n",
    "        if area > max_intersection_area:\n",
    "            max_intersection_area = area\n",
    "            best_match = rect\n",
    "\n",
    "    target_area = rectangle_area(target_rect)\n",
    "\n",
    "    if target_area == 0:\n",
    "        return best_match, max_intersection_area, 0\n",
    "\n",
    "    shared_percentage = (max_intersection_area / target_area) * 100\n",
    "\n",
    "    lambda_buttom = abs(target_rect[3] - best_match[3])\n",
    "    return best_match, max_intersection_area, shared_percentage, lambda_buttom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_directory_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(predicted_truths, ground_truths):\n",
    "    sum = 0\n",
    "    for prediction,truth in zip(predicted_truths, ground_truths):\n",
    "        if prediction == truth:\n",
    "            sum += 1\n",
    "    return sum / len(predicted_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = load_images('train/Task1')\n",
    "train_queries = load_queries('train/Task1')\n",
    "lane_images = load_images('train/Task1/full-configuration-templates')\n",
    "lane_pins = load_lane_pins('train/Task1/full-configuration-templates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pin in lane_pins[2]:\n",
    "    cv2.rectangle(lane_images[2], (pin[0], pin[1]),\n",
    "                          (pin[2], pin[3]), (255, 0, 0), 2)\n",
    "    display_image(lane_images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching score for lane 1: 0.5485676527023315\n",
      "Matching score for lane 2: 0.5191406011581421\n",
      "Matching score for lane 3: 0.6252387166023254\n",
      "Matching score for lane 4: 0.5294371843338013\n",
      "\n",
      "0: 384x640 7 bottles, 6 vases, 1867.9ms\n",
      "Speed: 2.0ms preprocess, 1867.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6415997743606567\n",
      "Matching score for lane 2: 0.5492364168167114\n",
      "Matching score for lane 3: 0.6739968657493591\n",
      "Matching score for lane 4: 0.6053139567375183\n",
      "\n",
      "0: 384x640 1 vase, 1893.2ms\n",
      "Speed: 1.0ms preprocess, 1893.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5710817575454712\n",
      "Matching score for lane 2: 0.5454027056694031\n",
      "Matching score for lane 3: 0.5569331645965576\n",
      "Matching score for lane 4: 0.6997135877609253\n",
      "\n",
      "0: 384x640 2 bottles, 5 vases, 1890.3ms\n",
      "Speed: 3.1ms preprocess, 1890.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5628028512001038\n",
      "Matching score for lane 2: 0.5227237939834595\n",
      "Matching score for lane 3: 0.5778488516807556\n",
      "Matching score for lane 4: 0.7006427645683289\n",
      "\n",
      "0: 384x640 1 bottle, 5 vases, 1872.2ms\n",
      "Speed: 2.0ms preprocess, 1872.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.665964663028717\n",
      "Matching score for lane 2: 0.5505497455596924\n",
      "Matching score for lane 3: 0.6502473950386047\n",
      "Matching score for lane 4: 0.6849681735038757\n",
      "\n",
      "0: 384x640 1 bottle, 3 vases, 1887.2ms\n",
      "Speed: 1.0ms preprocess, 1887.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5404641032218933\n",
      "Matching score for lane 2: 0.7403372526168823\n",
      "Matching score for lane 3: 0.5273281335830688\n",
      "Matching score for lane 4: 0.5529061555862427\n",
      "\n",
      "0: 384x640 4 vases, 1875.6ms\n",
      "Speed: 1.0ms preprocess, 1875.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5569173097610474\n",
      "Matching score for lane 2: 0.6133171319961548\n",
      "Matching score for lane 3: 0.5214744806289673\n",
      "Matching score for lane 4: 0.5439116358757019\n",
      "\n",
      "0: 384x640 1 bottle, 1 vase, 1893.3ms\n",
      "Speed: 2.0ms preprocess, 1893.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.7683120369911194\n",
      "Matching score for lane 2: 0.4976001977920532\n",
      "Matching score for lane 3: 0.5750628709793091\n",
      "Matching score for lane 4: 0.6164221167564392\n",
      "\n",
      "0: 384x640 5 vases, 1923.1ms\n",
      "Speed: 3.0ms preprocess, 1923.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6023056507110596\n",
      "Matching score for lane 2: 0.5311355590820312\n",
      "Matching score for lane 3: 0.640926718711853\n",
      "Matching score for lane 4: 0.598311185836792\n",
      "\n",
      "0: 384x640 1 bottle, 1894.9ms\n",
      "Speed: 1.0ms preprocess, 1894.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6030791401863098\n",
      "Matching score for lane 2: 0.5418497323989868\n",
      "Matching score for lane 3: 0.7183843851089478\n",
      "Matching score for lane 4: 0.603600800037384\n",
      "\n",
      "0: 384x640 1 bottle, 2 vases, 1892.3ms\n",
      "Speed: 2.0ms preprocess, 1892.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6400154232978821\n",
      "Matching score for lane 2: 0.9830348491668701\n",
      "Matching score for lane 3: 0.6217362284660339\n",
      "Matching score for lane 4: 0.6505507230758667\n",
      "\n",
      "0: 384x640 14 vases, 1870.6ms\n",
      "Speed: 2.0ms preprocess, 1870.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5140662789344788\n",
      "Matching score for lane 2: 0.5896406769752502\n",
      "Matching score for lane 3: 0.9066956043243408\n",
      "Matching score for lane 4: 0.5868517756462097\n",
      "\n",
      "0: 384x640 10 vases, 1852.4ms\n",
      "Speed: 2.0ms preprocess, 1852.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6806647777557373\n",
      "Matching score for lane 2: 0.6498974561691284\n",
      "Matching score for lane 3: 0.6316078901290894\n",
      "Matching score for lane 4: 0.9395940899848938\n",
      "\n",
      "0: 384x640 9 vases, 1852.1ms\n",
      "Speed: 2.0ms preprocess, 1852.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5520487427711487\n",
      "Matching score for lane 2: 0.4570470452308655\n",
      "Matching score for lane 3: 0.5664501190185547\n",
      "Matching score for lane 4: 0.5720298886299133\n",
      "\n",
      "0: 384x640 (no detections), 1866.6ms\n",
      "Speed: 2.0ms preprocess, 1866.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.569514274597168\n",
      "Matching score for lane 2: 0.5290113687515259\n",
      "Matching score for lane 3: 0.6324310302734375\n",
      "Matching score for lane 4: 0.5987030863761902\n",
      "\n",
      "0: 384x640 3 bottles, 1877.1ms\n",
      "Speed: 2.0ms preprocess, 1877.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5866838693618774\n",
      "Matching score for lane 2: 0.48005032539367676\n",
      "Matching score for lane 3: 0.6736315488815308\n",
      "Matching score for lane 4: 0.5292448401451111\n",
      "\n",
      "0: 384x640 5 vases, 1874.6ms\n",
      "Speed: 3.0ms preprocess, 1874.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6131934523582458\n",
      "Matching score for lane 2: 0.4164328873157501\n",
      "Matching score for lane 3: 0.5139593482017517\n",
      "Matching score for lane 4: 0.44742336869239807\n",
      "\n",
      "0: 384x640 6 bottles, 1870.3ms\n",
      "Speed: 2.0ms preprocess, 1870.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.6803554892539978\n",
      "Matching score for lane 2: 0.6005606055259705\n",
      "Matching score for lane 3: 0.6878368854522705\n",
      "Matching score for lane 4: 0.8551363945007324\n",
      "\n",
      "0: 384x640 11 vases, 1858.1ms\n",
      "Speed: 2.0ms preprocess, 1858.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5545879006385803\n",
      "Matching score for lane 2: 0.4948002099990845\n",
      "Matching score for lane 3: 0.62039715051651\n",
      "Matching score for lane 4: 0.6212134957313538\n",
      "\n",
      "0: 384x640 1 bottle, 1 vase, 1848.5ms\n",
      "Speed: 3.0ms preprocess, 1848.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5209252238273621\n",
      "Matching score for lane 2: 0.40559592843055725\n",
      "Matching score for lane 3: 0.5646438598632812\n",
      "Matching score for lane 4: 0.5806806087493896\n",
      "\n",
      "0: 384x640 1 bottle, 1 vase, 1864.6ms\n",
      "Speed: 2.0ms preprocess, 1864.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.678844690322876\n",
      "Matching score for lane 2: 0.5735830664634705\n",
      "Matching score for lane 3: 0.6629273891448975\n",
      "Matching score for lane 4: 0.70187908411026\n",
      "\n",
      "0: 384x640 4 vases, 1848.7ms\n",
      "Speed: 1.0ms preprocess, 1848.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5994573831558228\n",
      "Matching score for lane 2: 0.5044189691543579\n",
      "Matching score for lane 3: 0.7054927349090576\n",
      "Matching score for lane 4: 0.5562057495117188\n",
      "\n",
      "0: 384x640 2 bottles, 1 vase, 1855.5ms\n",
      "Speed: 2.0ms preprocess, 1855.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.8830505609512329\n",
      "Matching score for lane 2: 0.6400747895240784\n",
      "Matching score for lane 3: 0.6502485871315002\n",
      "Matching score for lane 4: 0.674315869808197\n",
      "\n",
      "0: 384x640 11 vases, 1858.8ms\n",
      "Speed: 3.0ms preprocess, 1858.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5489107370376587\n",
      "Matching score for lane 2: 0.391487717628479\n",
      "Matching score for lane 3: 0.4939780533313751\n",
      "Matching score for lane 4: 0.43041422963142395\n",
      "\n",
      "0: 384x640 3 bottles, 1851.6ms\n",
      "Speed: 1.0ms preprocess, 1851.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Matching score for lane 1: 0.5891476273536682\n",
      "Matching score for lane 2: 0.41731324791908264\n",
      "Matching score for lane 3: 0.5223411917686462\n",
      "Matching score for lane 4: 0.46126869320869446\n",
      "\n",
      "0: 384x640 3 bottles, 1 vase, 1867.4ms\n",
      "Speed: 2.0ms preprocess, 1867.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for image, query in zip(train_images, train_queries):\n",
    "    #Find from which lane was the image taken from.\n",
    "    lane, _, _ = classify_lane(image, lane_images[0], lane_images[1], lane_images[2], lane_images[3])\n",
    "\n",
    "    #Get the full pins positions for the specific lane.\n",
    "    full_pins_pos = lane_pins[lane-1]\n",
    "\n",
    "    #Detect the pins for the current image.\n",
    "    pins_pos = get_sorted_pins_position(model, image, classes=[39,75], conf=0.02, verbose=0)\n",
    "\n",
    "    detection_list = []\n",
    "    for input_pin in query[1]:\n",
    "        #For each original input pi, positon in the lane find the one in the image with the best_match over surface and position.\n",
    "        input_pin_pos = full_pins_pos[input_pin-1]\n",
    "        best_match, max_intersection_area, shared_percentage, lambda_buttom = find_best_matching_rectangle(input_pin_pos, pins_pos)\n",
    "        \n",
    "        #For a detected pin to be valid it needs to share 30% of the same surface as the original\n",
    "        #and the offset between buttom should be smaller then 10 pixels.\n",
    "        if shared_percentage > 27:  #and lambda_buttom < 10:\n",
    "            detection_list.append(1)\n",
    "        else:\n",
    "            detection_list.append(0)\n",
    "\n",
    "    if i<10:\n",
    "        file_path = os.path.join(f\"{os.getcwd()}\\\\train\\\\Task1\\\\predited-truth\", f\"0{i}_pt.txt\")\n",
    "    else:\n",
    "        file_path = os.path.join(f\"{os.getcwd()}\\\\train\\\\Task1\\\\predited-truth\", f\"{i}_pt.txt\")\n",
    "\n",
    "    ensure_directory_exists(os.path.dirname(file_path))\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(f\"{query[0]}\\n\")\n",
    "        for q,response in zip(query[1], detection_list):\n",
    "            file.write(f\"{q} {response}\\n\")\n",
    "\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_truths = load_results(\"train/Task1/predited-truth\")\n",
    "ground_truths = load_results(\"train/Task1/ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_accuracy(predicted_truths, ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
